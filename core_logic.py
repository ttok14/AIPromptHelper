# core_logic.py

import vertexai
from vertexai.generative_models import GenerativeModel
from vertexai.preview import caching

import os
import re
from datetime import datetime
from PySide6.QtCore import QObject, Signal, QRunnable, Slot

class VariableResolver:
    def __init__(self, variables):
        self.variables = {var.name: var.value for var in variables.values()}; self.var_pattern = re.compile(r"\{([^}]+)\}")
    def resolve(self, text, context_vars=None, visited=None):
        if visited is None: visited = set()
        if context_vars is None: context_vars = {}
        if len(visited) > len(self.variables) + len(context_vars): raise ValueError(f"ë³€ìˆ˜ ì°¸ì¡° ê¹Šì´ ì´ˆê³¼")
        resolved_text = text
        for match in reversed(list(self.var_pattern.finditer(text))):
            var_name = match.group(1)
            if var_name in visited: raise ValueError(f"ìˆœí™˜ ë³€ìˆ˜ ì°¸ì¡° ì˜¤ë¥˜: {' -> '.join(list(visited))} -> {var_name}")
            resolved_value = None
            if var_name in context_vars: resolved_value = context_vars[var_name]
            elif var_name in self.variables:
                new_visited = visited.copy(); new_visited.add(var_name)
                resolved_value = self.resolve(self.variables[var_name], context_vars, new_visited)
            if resolved_value is not None:
                start, end = match.span(); resolved_text = resolved_text[:start] + resolved_value + resolved_text[end:]
        return resolved_text

class TaskRunnerSignals(QObject):
    log_message = Signal(str); finished = Signal(); error = Signal(str)

class TaskRunner(QRunnable):
    def __init__(self, api_key, model_name, variables, tasks_in_order, 
                 output_folder, output_extension, log_folder, cached_content_name=None):
        super().__init__()
        self.signals = TaskRunnerSignals()
        self.api_key = api_key; self.model_name = model_name; self.variables = variables
        self.tasks_in_order = tasks_in_order; self.output_folder = output_folder
        self.output_extension = output_extension; self.log_folder = log_folder
        self.cached_content_name = cached_content_name
        self.is_running = True; self.log_filepath = None
    
    def _file_log(self, message):
        if not self.log_folder: return
        if not self.log_filepath:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S"); self.log_filepath = os.path.join(self.log_folder, f"log_{timestamp}.txt")
            try: os.makedirs(self.log_folder, exist_ok=True)
            except OSError as e: self.signals.log_message.emit(f"ë¡œê·¸ í´ë” ìƒì„± ì‹¤íŒ¨: {e}"); self.log_folder = None; return
        with open(self.log_filepath, 'a', encoding='utf-8') as f: f.write(f"{datetime.now().strftime('%H:%M:%S')} - {message}\n")

    def _log(self, message): self.signals.log_message.emit(message); self._file_log(message)

    @Slot()
    def run(self):
        self._log("="*40); self._log("ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        try:
            project_id = os.getenv("PROJECT_ID"); location = os.getenv("LOCATION")
            vertexai.init(project=project_id, location=location)
            
            model = None
            if self.cached_content_name:
                if not project_id or not location:
                    raise ValueError(".env íŒŒì¼ì— Vertex AI ì‚¬ìš©ì„ ìœ„í•œ PROJECT_IDì™€ LOCATIONì´ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
                self._log(f"Vertex AI ì´ˆê¸°í™” ì™„ë£Œ (Project: {project_id}, Location: {location})")
                
                cached_content = caching.CachedContent.get(self.cached_content_name)
                model = GenerativeModel.from_cached_content(cached_content=cached_content)
                # *** ìˆ˜ì •ë¨: model.model_name -> cached_content.model_name ***
                self._log(f"ğŸ§  ìºì‹œ '{os.path.basename(self.cached_content_name)}' (ëª¨ë¸: {os.path.basename(cached_content.model_name)}) ì‚¬ìš©")
            else:
                model = GenerativeModel(self.model_name)
                self._log(f"ğŸ§  ëª¨ë¸ '{self.model_name}' ì§ì ‘ ì‚¬ìš©")
            
            resolver = VariableResolver(self.variables)
            os.makedirs(self.output_folder, exist_ok=True); self._log(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ í´ë”: {self.output_folder}")

            for task in self.tasks_in_order:
                if not self.is_running: self._log("ğŸ”´ ì‘ì—…ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."); break
                
                resolved_task_name = resolver.resolve(task.name)
                self._log(f"\nâ–¶ íƒœìŠ¤í¬ '{task.name}' (-> '{resolved_task_name}') ì‹¤í–‰ ì‹œì‘...")
                
                final_prompt = resolver.resolve(task.prompt)
                self._log("  - í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ. API ìš”ì²­ ì¤‘...")
                
                response = model.generate_content(final_prompt)
                response_text = response.text
                self._log("  - API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ.")

                output_template = task.output_template if task.output_template.strip() else "{RESPONSE}"
                context_vars = {"RESPONSE": response_text}
                final_output_content = resolver.resolve(output_template, context_vars)

                safe_task_name = "".join(c if c.isalnum() or c in ' -_' else '_' for c in resolved_task_name)
                ext = self.output_extension if self.output_extension.startswith('.') else '.' + self.output_extension
                filepath = os.path.join(self.output_folder, f"{safe_task_name}{ext}")
                
                with open(filepath, "w", encoding="utf-8") as f: f.write(final_output_content)
                self._log(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")

        except Exception as e:
            error_msg = f"âŒ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}"
            self._log(error_msg); self.signals.error.emit(error_msg)
        finally:
            if self.is_running: self._log("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            self._log("="*40); self.signals.finished.emit()
            
    def stop(self): self.is_running = False